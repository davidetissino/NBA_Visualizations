library(XML)
wiki_url <- "https://en.wikipedia.org/wiki/Leonardo_da_Vinci"
wiki_read <- readLines(wiki_url, encoding = "UTF-8")
parsed_wiki <- htmlParse(wiki_read, encoding = "UTF-8")
wiki_intro_text <- parsed_wiki["//p"]
View(wiki_intro_text)
wiki_intro_text[[4]]
wiki-grid <- parsed_wiki['//grid-row']
wiki_grid <- parsed_wiki['//grid-row']
wiki_grid <- parsed_wiki['rid-row']
wiki_grid <- parsed_wiki['grid-row']
wiki_grid <- parsed_wiki['grid-cell']
wiki_grid <- parsed_wiki['/grid']
wiki_grid <- parsed_wiki['/grid-row']
readHTMLTable(wiki_read)
tab <- readLines(url, encoding = 'UTF-8')
url <- 'https://www.crunchbase.com/discover/organization.companies/9cd1fb458449c718af2a66fe9de44447'
tab <- readLines(url, encoding = 'UTF-8')
grid <- tab['//grid-row']
par <- htmlParse(tab, encoding = 'UTF-8')
grid <- tab['//grid-row']
grid <- tab['grid-row']
grid <- tab['grid-cell']
grid <- tab['//grid-cell']
grid <- tab['//p']
tab <- read_html(url) %>%
html_nodes('grid')
library(rvest)
library(tidyverse)
tab <- read_html(url) %>%
html_nodes('grid')
tab <- read_html(url) %>%
html_nodes('grid') %>%
html_table()
tab <- read_html(url) %>%
html_nodes('grid-row') %>%
html_table()
View(tab)
View(tab)
tab[[2]]
tab <- read_html(url) %>%
html_nodes('ng-star-inserted') %>%
html_table()
tab <- read_html(url) %>%
html_nodes('ng-star-inserted')
tab <- read_html(url) %>%
html_nodes('.ng-star-inserted') %>%
html_table()
View(tab)
tab <- read_html(url) %>%
html_nodes('.grid-container') %>%
html_table()
tab <- read_html(url) %>%
html_nodes('.ng-star-inserted') %>%
html_table()
# Read HTML content from a file
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d")
library(rvest)
library(tidyverse)
# Read HTML content from a file
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d")
library(rvest)
library(tidyverse)
# Read HTML content from a file
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d")
# Read HTML content from a file
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d",
user_agent('Mozilla/5.0'))
# Read HTML content from a file
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d")
url <- 'https://www.crunchbase.com/discover/organization.companies/9cd1fb458449c718af2a66fe9de44447'
tab <- readLines(url, encoding = 'UTF-8')
html_content <- read_html(url)
grid_rows <- html_content %>%
html_nodes("grid-row")
# Initialize empty list to store data
data_list <- list()
# Loop over each grid-row element
for (i in 1:length(grid_rows)) {
# Extract data from each grid-row element
row_data <- grid_rows[[i]] %>%
html_nodes("grid-cell") %>%
html_text()
# Store the extracted data in the list
data_list[[i]] <- row_data
}
# Convert the list to a data frame
df <- do.call(rbind, data_list)
# Clean up the data frame (if needed)
# Print or further process the data frame
print(df)
View(data_list)
df <- as.data.frame(data_list)
View(df)
# Use html_nodes to select all grid-row elements
grid_rows <- html_content %>%
html_nodes("grid-cell")
View(grid_rows)
# Use html_nodes to select all grid-row elements
grid_rows <- html_content %>%
html_nodes("grid-row")
View(df)
fin <- pivot_longer(df)
View(grid_rows)
url <- 'https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d'
html_content <- read_html(url)
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d")
html_content <- read_html(url)
library(rvest)
library(tidyverse)
# Read HTML content from a file
html_content <- read_html("https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d")
library(httr)
library(rvest)
url <- 'https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d'
ref <- GET(url, add_headers('user-agent' = 'Gov employment data scraper ([[your email]])'))
ref <- read_html() %>%
html_node('.ng-star-inserted') %>%
html_table()
ref <- read_html() %>%
html_node('.grid-container') %>%
html_table()
ref <- read_html() %>%
html_nodes('.grid-container') %>%
html_table()
# Read HTML content from a file
html_content <- read_html(url)
headers <- c(
`Connection` = 'keep-alive',
`Accept` = 'application/json, text/plain, */*',
`x-nba-stats-token` = 'true',
`X-NewRelic-ID` = 'VQECWF5UChAHUlNTBwgBVw==',
`User-Agent` = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36',
`x-nba-stats-origin` = 'stats',
`Sec-Fetch-Site` = 'same-origin',
`Sec-Fetch-Mode` = 'cors',
`Referer` = 'https://stats.nba.com/players/shooting/',
`Accept-Encoding` = 'gzip, deflate, br',
`Accept-Language` = 'en-US,en;q=0.9'
)
url <- 'https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d'
ref <- GET(url, add_headers(.headers = headers))
View(df)
ref <- read_html() %>%
html_nodes('.ng-star-inserted') %>%
html_table()
library(httr)
library(rvest)
headers <- c(
`Connection` = 'keep-alive',
`Accept` = 'application/json, text/plain, */*',
`x-nba-stats-token` = 'true',
`X-NewRelic-ID` = 'VQECWF5UChAHUlNTBwgBVw==',
`User-Agent` = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36',
`x-nba-stats-origin` = 'stats',
`Sec-Fetch-Site` = 'same-origin',
`Sec-Fetch-Mode` = 'cors',
`Referer` = 'https://stats.nba.com/players/shooting/',
`Accept-Encoding` = 'gzip, deflate, br',
`Accept-Language` = 'en-US,en;q=0.9'
)
url <- 'https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d'
ref <- GET(url, add_headers(.headers = headers))
headers <- c(
`Connection` = 'keep-alive',
`Accept` = 'application/json, text/plain, */*',
`x-nba-stats-token` = 'true',
`X-NewRelic-ID` = 'VQECWF5UChAHUlNTBwgBVw==',
`User-Agent` = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36',
`x-nba-stats-origin` = 'stats',
`Sec-Fetch-Site` = 'same-origin',
`Sec-Fetch-Mode` = 'cors',
`Referer` = 'https://www.crunchbase.com',
`Accept-Encoding` = 'gzip, deflate, br',
`Accept-Language` = 'en-US,en;q=0.9'
)
url <- 'https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d'
ref <- GET(url, add_headers(.headers = headers))
# Read HTML content from a file
html_content <- read_html(url)
headers <- c(
`Connection` = 'keep-alive',
`Accept` = 'application/json, text/plain, */*',
`x-nba-stats-token` = 'true',
`X-NewRelic-ID` = 'VQECWF5UChAHUlNTBwgBVw==',
`User-Agent` = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.87 Safari/537.36',
`x-nba-stats-origin` = 'stats',
`Sec-Fetch-Site` = 'same-origin',
`Sec-Fetch-Mode` = 'cors',
`Referer` = 'https://www.crunchbase.com',
`Accept-Encoding` = 'gzip, deflate, br',
`Accept-Language` = 'en-US,en;q=0.9'
)
url <- 'https://www.crunchbase.com/discover/organization.companies/4f5fec5925dcfa95b22cf045f573266d'
ref <- GET(url, add_headers(.headers = headers))
View(df)
